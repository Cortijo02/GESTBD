{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed3ab6f-97e2-41b5-b044-775a1c180c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa44875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743d4b4",
   "metadata": {},
   "source": [
    "## Funciones de limpieza y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd9b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if pd.isna(text) else str(text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"<br\\s*/?>\", \" \", text, flags=re.I)\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_by_chars(text: str, max_chars: int = 4000) -> List[str]:\n",
    "    \"\"\"Divide el texto en trozos por frases para no cortar a lo bruto.\"\"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return [text]\n",
    "    parts, current, count = [], [], 0\n",
    "    sentences = re.split(r\"(?<=[\\.\\!\\?])\\s+\", text)\n",
    "    for s in sentences:\n",
    "        if count + len(s) + 1 > max_chars and current:\n",
    "            parts.append(\" \".join(current).strip())\n",
    "            current, count = [s], len(s) + 1\n",
    "        else:\n",
    "            current.append(s)\n",
    "            count += len(s) + 1\n",
    "    if current:\n",
    "        parts.append(\" \".join(current).strip())\n",
    "    return parts\n",
    "\n",
    "\n",
    "def hash_text(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def save_minimal(df, out_path, summary_col):\n",
    "    required = [\"id\", \"grado\", summary_col]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise SystemExit(f\"Faltan columnas para exportar {missing}. Debe haber id, grado y {summary_col}.\")\n",
    "    df[[\"id\", \"grado\", summary_col]].to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b63989",
   "metadata": {},
   "source": [
    "## Función para resumir texto con Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903cc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama_summary(\n",
    "    text: str,\n",
    "    model: str,\n",
    "    max_words: int = 80,\n",
    "    temperature: float = 0.2,\n",
    "    num_predict: int = 240,\n",
    "    retries: int = 3,\n",
    "    sleep_sec: float = 1.5,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Pide un resumen en formato JSON {\"resumen\": \"...\"} al modelo local de Ollama.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"Eres un asistente que resume texto en ESPAÑOL de forma clara, fiel y concisa. \"\n",
    "        f\"Devuelve SOLO un JSON con la clave 'resumen', con un máximo de {max_words} palabras. \"\n",
    "        \"Mantén lo esencial (quién, qué, para qué) y nombres propios; elimina relleno, URLs y jerga. \"\n",
    "        \"Si la descripción está vacía o irrelevante, devuelve resumen vacío.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"Descripción:\\n{text}\\n\\nDevuelve: {{\\\"resumen\\\": \\\"...\\\"}}\"\n",
    "\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = ollama.generate(\n",
    "                model=model,\n",
    "                prompt=f\"<<SYS>>{system_prompt}<</SYS>>\\n\\n{user_prompt}\",\n",
    "                options={\"temperature\": temperature, \"num_predict\": num_predict},\n",
    "                format=\"json\",\n",
    "                stream=False,\n",
    "            )\n",
    "            raw = resp.get(\"response\", \"\").strip()\n",
    "            data = json.loads(raw)\n",
    "            resumen = data.get(\"resumen\", \"\").strip()\n",
    "            resumen = re.sub(r\"\\s+\", \" \", resumen)\n",
    "            resumen_words = resumen.split()\n",
    "            if len(resumen_words) > max_words:\n",
    "                resumen = \" \".join(resumen_words[:max_words])\n",
    "            return resumen\n",
    "        except Exception as e:\n",
    "            if attempt == retries:\n",
    "                return \"\"\n",
    "            time.sleep(sleep_sec * attempt)\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad3b4a",
   "metadata": {},
   "source": [
    "## Parámetros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf64a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CSV = \"./data/dummy_educacion_test.csv\"      \n",
    "OUT_CSV = \"./data/dummy_educacion_test_clean.csv\"           \n",
    "TEXT_COL = \"salidas\"                   \n",
    "SUMMARY_COL = \"resumen\"                    \n",
    "MODEL = \"llama3.1:8b\"                      \n",
    "MAX_WORDS = 75\n",
    "SAVE_EVERY = 25\n",
    "SKIP_EXISTING = True\n",
    "MAX_CHARS = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215ac56",
   "metadata": {},
   "source": [
    "## Procesamiento principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resumiendo:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(IN_CSV)\n",
    "if TEXT_COL not in df.columns:\n",
    "    raise SystemExit(f\"La columna '{TEXT_COL}' no existe en el CSV.\")\n",
    "\n",
    "if SUMMARY_COL not in df.columns:\n",
    "    df[SUMMARY_COL] = \"\"\n",
    "\n",
    "processed = 0\n",
    "\n",
    "for i in tqdm(range(len(df)), desc=\"Resumiendo\"):\n",
    "    if SKIP_EXISTING and isinstance(df.at[i, SUMMARY_COL], str) and df.at[i, SUMMARY_COL].strip():\n",
    "        continue\n",
    "\n",
    "    raw_text = df.at[i, TEXT_COL]\n",
    "    text = clean_text(raw_text)\n",
    "\n",
    "    if not text:\n",
    "        df.at[i, SUMMARY_COL] = \"\"\n",
    "    else:\n",
    "        chunks = chunk_by_chars(text, max_chars=MAX_CHARS)\n",
    "        if len(chunks) == 1:\n",
    "            resumen = call_ollama_summary(chunks[0], model=MODEL, max_words=MAX_WORDS)\n",
    "        else:\n",
    "            partials = [\n",
    "                call_ollama_summary(ch, model=MODEL, max_words=max(40, MAX_WORDS // 2))\n",
    "                for ch in chunks\n",
    "            ]\n",
    "            merged = \" \".join([p for p in partials if p]).strip()\n",
    "            resumen = call_ollama_summary(merged, model=MODEL, max_words=MAX_WORDS)\n",
    "\n",
    "        df.at[i, SUMMARY_COL] = resumen\n",
    "\n",
    "    processed += 1\n",
    "    if processed % SAVE_EVERY == 0:\n",
    "        save_minimal(df, OUT_CSV, SUMMARY_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9803907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado final\n",
    "save_minimal(df, OUT_CSV, SUMMARY_COL)\n",
    "print(f\"✅ Listo → {OUT_CSV}\")\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
