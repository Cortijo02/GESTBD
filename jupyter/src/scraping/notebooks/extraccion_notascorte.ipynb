{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0837e812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.8/site-packages (3.9.7)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import unicodedata\n",
    "\n",
    "!pip install rapidfuzz\n",
    "\n",
    "from rapidfuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e9fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.comunidad.madrid/servicios/educacion/publicaciones-interes-universitario\"\n",
    "html = requests.get(base_url).text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "pdf_links = [\n",
    "    a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
    "    if \"notas\" in a[\"href\"].lower() and a[\"href\"].endswith(\".pdf\")\n",
    "]\n",
    "\n",
    "if not pdf_links:\n",
    "    raise Exception(\"No se encontró el PDF de notas de corte en la página.\")\n",
    "\n",
    "pdf_url = pdf_links[0]\n",
    "if not pdf_url.startswith(\"http\"):\n",
    "    pdf_url = \"https://www.comunidad.madrid\" + pdf_url\n",
    "\n",
    "response = requests.get(pdf_url)\n",
    "pdf_bytes = BytesIO(response.content)\n",
    "\n",
    "filas = []\n",
    "año = 2025\n",
    "convocatoria = \"ordinaria\"\n",
    "\n",
    "with pdfplumber.open(pdf_bytes) as pdf:\n",
    "    universidad_actual = None\n",
    "    for page in pdf.pages:\n",
    "        texto = page.extract_text()\n",
    "        if not texto:\n",
    "            continue\n",
    "        uni_match = re.search(r\"(UNIVERSIDAD\\s+[A-ZÁÉÍÓÚÑ\\s]+?)(?:CURSO|\\n|$)\", texto)\n",
    "        if uni_match:\n",
    "            universidad_actual = uni_match.group(1).title().strip()\n",
    "        table = page.extract_table()\n",
    "        if not table:\n",
    "            continue\n",
    "        headers = table[0]\n",
    "        data_rows = table[1:]\n",
    "        for row in data_rows:\n",
    "            if not any(row):\n",
    "                continue\n",
    "            codigo, grado, *resto = row\n",
    "            if not grado or grado.lower().startswith(\"código\"):\n",
    "                continue\n",
    "            for i, nota in enumerate(resto):\n",
    "                if nota and re.search(r\"\\d\", nota):\n",
    "                    grupo = f\"Grupo {i//2 + 1}\"\n",
    "                    valor = re.search(r\"[\\d,]+\", nota)\n",
    "                    if valor:\n",
    "                        filas.append({\n",
    "                            \"universidad\": universidad_actual,\n",
    "                            \"grado\": grado.strip(),\n",
    "                            \"grupo\": grupo,\n",
    "                            \"nota\": valor.group(0).replace(\",\", \".\"),\n",
    "                            \"año\": año,\n",
    "                            \"convocatoria\": convocatoria\n",
    "                        })\n",
    "\n",
    "df_notas = pd.DataFrame(filas)\n",
    "df_notas.drop_duplicates(subset=[\"universidad\", \"grado\", \"grupo\"], inplace=True)\n",
    "\n",
    "def agrupar_similares(valores, umbral=85, umbral_siglas=85):\n",
    "    valores_unicos = list(valores.dropna().unique())\n",
    "    grupos = {}\n",
    "    usados = set()\n",
    "    def siglas(texto):\n",
    "        return ''.join([c for c in texto if c.isupper()])\n",
    "    for v in valores_unicos:\n",
    "        if v in usados:\n",
    "            continue\n",
    "        grupo = [v]\n",
    "        usados.add(v)\n",
    "        siglas_v = siglas(v)\n",
    "        for otro in valores_unicos:\n",
    "            if otro in usados:\n",
    "                continue\n",
    "            simil = fuzz.token_sort_ratio(v, otro)\n",
    "            siglas_otro = siglas(otro)\n",
    "            if simil >= umbral:\n",
    "                grupo.append(otro)\n",
    "                usados.add(otro)\n",
    "                continue\n",
    "            if siglas_v and siglas_otro:\n",
    "                simil_siglas = fuzz.ratio(siglas_v, siglas_otro)\n",
    "                if simil_siglas >= umbral_siglas:\n",
    "                    grupo.append(otro)\n",
    "                    usados.add(otro)\n",
    "                    continue\n",
    "        cambio = grupo[0]\n",
    "        for previo in grupo:\n",
    "            grupos[previo] = cambio\n",
    "    return grupos\n",
    "\n",
    "def normalizar_texto_general(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return texto\n",
    "    texto = texto.strip().lower()\n",
    "    texto = ''.join(c for c in unicodedata.normalize('NFKD', texto) if not unicodedata.combining(c))\n",
    "    texto = re.sub(r'\\([^)]*\\)', '', texto)\n",
    "    texto = re.sub(r'\\s*-\\s*', ' - ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    texto = texto.title()\n",
    "    excepciones = [\"De\", \"Del\", \"La\", \"Las\", \"El\", \"Los\", \"Y\", \"En\", \"Por\", \"Para\"]\n",
    "    for exc in excepciones:\n",
    "        texto = re.sub(rf'\\b{exc}\\b', exc.lower(), texto)\n",
    "    return texto\n",
    "\n",
    "def normalizar_universidad(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return texto\n",
    "    texto = texto.strip()\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    texto = texto.title()\n",
    "    return texto\n",
    "\n",
    "mapa_universidades = agrupar_similares(df_notas['universidad'])\n",
    "df_notas['universidad'] = df_notas['universidad'].map(mapa_universidades).fillna(df_notas['universidad'])\n",
    "df_notas['universidad'] = df_notas['universidad'].apply(normalizar_universidad)\n",
    "df_notas['grado'] = df_notas['grado'].apply(normalizar_texto_general)\n",
    "\n",
    "df_notas_expandidas = []\n",
    "for _, row in df_notas.iterrows():\n",
    "    grados = [g.strip() for g in row[\"grado\"].split(\" - \")]\n",
    "    for g in grados:\n",
    "        nueva = row.copy()\n",
    "        nueva[\"grado\"] = g\n",
    "        df_notas_expandidas.append(nueva)\n",
    "\n",
    "df_notas = pd.DataFrame(df_notas_expandidas)\n",
    "df_notas.to_csv(\"../Input/notas_corte.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
